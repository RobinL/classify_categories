{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Observations\n",
    "\n",
    "Make sure we tidy up unicode \n",
    "\n",
    "X T C -> XTC\n",
    "\n",
    "Make sure we're not deleting the 'x' from things like 10x\n",
    "\n",
    "Remove brackets, commas, exclamation marksbut not currency symbols\n",
    "\n",
    "Replace \"/\" with \" \"\n",
    "\n",
    "\n",
    "Replace number mg and number g with space\n",
    "Replace numberxnumber with number x number\n",
    "\n",
    "https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getdata import x_train, x_test, y_train, y_test, x_train_all, x_test_all\n",
    "from tidy_data import TidySymbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how it's dealing with special characters by default\n",
    "x_train = x_train[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection or raw documents into a matrix of TD-IDF features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "# Vectorizer is an object that we can then pass data into and it will transform it appropriately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('tidy', TidySymbols()),\n",
    "    ('vect', CountVectorizer(token_pattern=\"[^ ]+\")),\n",
    "    ('tfidf', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(x_train)\n",
    "\", \".join(text_clf.named_steps[\"vect\"].get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u\"\\U00002725\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=\"[^ \\(\\)\\[\\]\\!\\+\\*\\/\\-]+\")\n",
    "m = vectorizer.fit_transform(x_train).todense()\n",
    "df_tdif = pd.DataFrame(m)\n",
    "df_tdif.columns = vectorizer.get_feature_names()\n",
    "\n",
    "print(\", \".join(vectorizer.get_feature_names()))\n",
    "df_tdif.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(strip_accents=False)\n",
    "m = vectorizer.fit_transform(x_train).todense()\n",
    "df_tdif = pd.DataFrame(m)\n",
    "df_tdif.columns = vectorizer.get_feature_names()\n",
    "\n",
    "print(\", \".join(vectorizer.get_feature_names()))\n",
    "df_tdif.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = u' ♦£11♦♦♦ hel'\n",
    "\n",
    "s = pd.Series(text)\n",
    "emoji_pattern = re.compile(\"([\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002600-\\U000026FF\"  # misc sumbols\n",
    "                               \"]+)\", flags=re.UNICODE)\n",
    "s.str.replace(emoji_pattern, \" \\\\1 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = u'12mg and 136 mg amg of coke'\n",
    "s = pd.Series([text])\n",
    "\n",
    "p = re.compile(\"(\\d+) mg\")\n",
    "s.str.replace(p, \"\\\\1mg\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = u'hi / hello /hello!!* 1/2'\n",
    "X = pd.Series([text])\n",
    "\n",
    "X = X.str.replace(r\"\\!|\\+|\\*|\\/|\\-\",\"\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hi()\n",
    "h.f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
